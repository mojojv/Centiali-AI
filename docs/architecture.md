# Arquitectura TÃ©cnica - Centrally

## ğŸ“ VisiÃ³n General

Centrally es una plataforma enterprise de analÃ­tica de datos de transporte urbano construida con arquitectura modular de 9 capas, diseÃ±ada para escalar horizontalmente y soportar miles de usuarios concurrentes.

## ğŸ—ï¸ Arquitectura de Capas

### Diagrama de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CAPA 6: VISUALIZACIÃ“N                        â”‚
â”‚                    (Dash + Plotly + Leaflet)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                               â”‚
             â”‚                               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CAPA 7: BACKEND API      â”‚   â”‚   CAPA 5: LLMs & RAG          â”‚
â”‚     (FastAPI + JWT)       â”‚   â”‚  (LangChain + FAISS)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                               â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             CAPA 4: ANALÃTICA & MODELOS ML                     â”‚
â”‚         (scikit-learn + XGBoost + Prophet + MLflow)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          CAPA 3: ALMACENAMIENTO (PostgreSQL + PostGIS)         â”‚
â”‚                      Star Schema: dim_* + fact_*                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       CAPA 2: TRANSFORMACIÃ“N ETL/ELT (pandas + dbt)            â”‚
â”‚              Staging â†’ Processing â†’ Analytics                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      CAPA 1: INGESTA (APIs + CSV + Excel + GeoJSON)            â”‚
â”‚              Validators (Pandera) + Metadata                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–²
             â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  DATA SOURCES   â”‚
    â”‚  (Datos Abiertosâ”‚
    â”‚   MedellÃ­n)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CAPA 8:    â”‚   GOBERNANZA DE DATOS                      â”‚
â”‚  Transversalâ”‚   Metadata + Lineage + Quality + Logs      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CAPA 9:    â”‚   DESPLIEGUE & ORQUESTACIÃ“N               â”‚
â”‚  Infraest.  â”‚   Docker + K8s + Airflow/Prefect + CI/CD  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

## ğŸ—„ï¸ Modelo de Datos - Star Schema

### Dimensiones

**dim_tiempo**
- tiempo_id (PK)
- fecha, hora
- dia_semana, mes, trimestre, anio
- es_festivo, es_fin_semana

**dim_zona**
- zona_id (PK)
- codigo_zona
- nombre_zona, tipo_zona
- geometria (PostGIS POLYGON)
- area_km2, poblacion

**dim_tipo_vehiculo**
- vehiculo_id (PK)
- codigo_vehiculo
- nombre_vehiculo, categoria

**dim_tipo_incidente**
- incidente_tipo_id (PK)
- codigo_incidente
- nombre_incidente, categoria, gravedad

### Hechos

**fact_trafico**
- trafico_id (PK)
- tiempo_id (FK), zona_id (FK), vehiculo_id (FK)
- MÃ©tricas: volumen_vehicular, velocidad_promedio, tiempo_recorrido_seg, nivel_congestion

**fact_incidentes**
- incidente_id (PK)
- tiempo_id (FK), zona_id (FK), incidente_tipo_id (FK)
- latitud, longitud, ubicacion (PostGIS POINT)
- descripcion, afectacion_vial, tiempo_resolucion_min

## ğŸ”„ Flujo de Datos

1. **Ingesta** â†’ APIs/CSV llegan a `data_ingestion/raw/`
2. **ValidaciÃ³n** â†’ Pandera valida esquemas
3. **Staging** â†’ Datos limpios en `data_processing/staging/`
4. **TransformaciÃ³n** â†’ ETL genera features en `data_processing/analytics/`
5. **Carga** â†’ PostgreSQL Star Schema
6. **AnalÃ­tica** â†’ Modelos ML generan insights
7. **VisualizaciÃ³n** â†’ Dash consume vÃ­a API
8. **LLMs** â†’ RAG responde preguntas sobre datos

## ğŸ” Seguridad

- **AutenticaciÃ³n**: JWT con roles (analista, decisor, admin)
- **AutorizaciÃ³n**: RBAC en endpoints FastAPI
- **Datos sensibles**: No se almacenan datos personales
- **Transporte**: HTTPS en producciÃ³n
- **Secrets**: Variables de entorno (.env)

## ğŸ“Š Escalabilidad

### Horizontal
- Dashboard Dash: MÃºltiples instancias detrÃ¡s de load balancer
- API FastAPI: Auto-scaling en cloud
- PostgreSQL: Read replicas para consultas

### Vertical
- Batch processing para ETL grandes
- CachÃ© con Redis (opcional)
- CompresiÃ³n de datos histÃ³ricos

## ğŸš€ TecnologÃ­as Clave

| Capa | TecnologÃ­as |
|------|-------------|
| Frontend | Dash 2.14, Plotly, Dash-Leaflet, Bootstrap |
| Backend | FastAPI 0.108, Uvicorn, Pydantic |
| Base de Datos | PostgreSQL 15 + PostGIS 3.3, DuckDB |
| ETL | pandas, dbt, Pandera |
| ML | scikit-learn, XGBoost, Prophet, MLflow |
| LLMs | LangChain, FAISS, OpenAI/Llama |
| DevOps | Docker, GitHub Actions, pytest |

## ğŸ“ Estructura de Almacenamiento

```
data_storage/
â”œâ”€â”€ postgres_data/          # Volumen Docker PostgreSQL
â”œâ”€â”€ duckdb_data/            # DuckDB para prototipado local
â””â”€â”€ db_scripts/
    â”œâ”€â”€ init.sql            # InicializaciÃ³n de schema
    â””â”€â”€ migrations/         # Migraciones (Alembic)
```

## ğŸ”§ ConfiguraciÃ³n de Entorno

Ver `.env.example` para variables requeridas:
- `DATABASE_URL`: ConexiÃ³n PostgreSQL
- `OPENAI_API_KEY`: Para LLMs
- `JWT_SECRET_KEY`: AutenticaciÃ³n
- `DASH_SECRET_KEY`: Sesiones Dash

## ğŸ§ª Estrategia de Testing

- **Unit Tests**: pytest para funciones individuales
- **Integration Tests**: Tests de pipelines completos
- **E2E Tests**: Selenium para dashboard
- **Cobertura mÃ­nima**: 80%

## ğŸ“ Gobernanza de Datos

### Metadata Tracking
- Tabla `metadata_ingesta`: Registro de todas las ingestas
- Campos: dataset_name, timestamp, registros_procesados, estado

### Data Lineage
- Tabla `metadata_lineage`: Trazabilidad de transformaciones
- Tracking: tabla_origen â†’ transformaciÃ³n â†’ tabla_destino

### Calidad de Datos
- ValidaciÃ³n con Pandera en ingesta
- Checks de integridad referencial en PostgreSQL
- Alertas automÃ¡ticas por anomalÃ­as

## ğŸŒ Despliegue

### Local (Desarrollo)
```bash
docker-compose up -d
python dashboard/app.py
```

### Cloud (ProducciÃ³n)
- **Azure**: App Service + PostgreSQL Flexible Server
- **AWS**: ECS + RDS PostgreSQL
- **Load Balancer**: Nginx
- **CI/CD**: GitHub Actions â†’ Docker Registry â†’ Cloud

## ğŸ”® Roadmap TÃ©cnico

**Fase 1 (MVP)**: âœ“ Estructura base, ingesta, dashboard bÃ¡sico
**Fase 2**: Modelos ML, mapas geoespaciales, Airflow
**Fase 3**: LLMs integrados, chat conversacional, reportes automÃ¡ticos

---

**Ãšltima actualizaciÃ³n**: 2026-01-13
