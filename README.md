# ğŸ™ï¸ Centrally - Plataforma de AnalÃ­tica de Datos de Transporte Urbano

## ğŸ“‹ DescripciÃ³n
**Centrally** es una plataforma integral de analÃ­tica, visualizaciÃ³n y toma de decisiones basada en datos de transporte urbano para la **AlcaldÃ­a de MedellÃ­n**. Combina ETL avanzado, modelos de Machine Learning, visualizaciones interactivas y capacidades conversacionales con LLMs para impulsar decisiones informadas en movilidad urbana.

## ğŸ¯ Objetivos
- **Centralizar datos** de mÃºltiples fuentes (APIs abiertas, CSV, Excel, GeoJSON)
- **Transformar datos** mediante pipelines ETL/ELT robustos
- **Analizar** con modelos predictivos, clustering y forecasting
- **Visualizar** con dashboards interactivos en Dash
- **Conversar con datos** mediante LLMs y RAG
- **Gobernar datos** con metadata, lineage y calidad

## ğŸ—ï¸ Arquitectura

### Capas del Sistema
1. **Ingesta de Datos**: ConexiÃ³n a fuentes abiertas, validaciÃ³n con Pandera
2. **TransformaciÃ³n ETL/ELT**: Limpieza, normalizaciÃ³n, Star Schema
3. **Almacenamiento**: PostgreSQL + PostGIS, DuckDB
4. **AnalÃ­tica & ML**: Modelos predictivos, anÃ¡lisis espacial, MLflow
5. **LLMs & RAG**: Consultas conversacionales, reportes automÃ¡ticos
6. **VisualizaciÃ³n**: Dashboards Dash con Plotly, mapas interactivos
7. **Backend**: FastAPI con autenticaciÃ³n JWT
8. **Gobernanza**: Metadata, logging, data lineage
9. **Despliegue**: Docker Compose, Cloud (Azure/AWS)

### Stack TecnolÃ³gico
- **Lenguaje**: Python 3.10+
- **Frontend**: Dash, Plotly, Dash-Leaflet, Bootstrap
- **Backend**: FastAPI, Uvicorn, Gunicorn
- **Datos**: pandas, geopandas, dbt, pandera
- **DB**: PostgreSQL + PostGIS, DuckDB
- **ML**: scikit-learn, XGBoost, Prophet, MLflow
- **LLMs**: LangChain, FAISS/ChromaDB, OpenAI/Llama
- **DevOps**: Docker, GitHub Actions, pytest, black, flake8

## ğŸ“ Estructura del Proyecto

```
centrally/
â”œâ”€â”€ data_ingestion/          # Capa 1: Ingesta de datos
â”‚   â”œâ”€â”€ raw/                 # Datos crudos
â”‚   â”œâ”€â”€ scripts/             # Scripts de ingesta (API, CSV, etc.)
â”‚   â””â”€â”€ validators.py        # ValidaciÃ³n con Pandera
â”œâ”€â”€ data_processing/         # Capa 2: TransformaciÃ³n ETL/ELT
â”‚   â”œâ”€â”€ staging/             # Datos procesados intermedios
â”‚   â”œâ”€â”€ transformations/     # Scripts de limpieza y normalizaciÃ³n
â”‚   â”œâ”€â”€ features/            # Feature engineering
â”‚   â””â”€â”€ schemas/             # Definiciones Star Schema
â”œâ”€â”€ data_storage/            # Capa 3: Almacenamiento
â”‚   â”œâ”€â”€ postgres_data/       # Volumen PostgreSQL (Docker)
â”‚   â”œâ”€â”€ duckdb_data/         # DuckDB local
â”‚   â””â”€â”€ db_scripts/          # Scripts DDL/DML
â”œâ”€â”€ models/                  # Capa 4: AnalÃ­tica y ML
â”‚   â”œâ”€â”€ descriptive/         # KPIs, series temporales
â”‚   â”œâ”€â”€ predictive/          # Modelos de ML
â”‚   â”œâ”€â”€ spatial/             # AnÃ¡lisis geoespacial
â”‚   â”œâ”€â”€ evaluation/          # MÃ©tricas y evaluaciÃ³n
â”‚   â””â”€â”€ trained_models/      # Modelos serializados
â”œâ”€â”€ llm/                     # Capa 5: LLMs y RAG
â”‚   â”œâ”€â”€ prompts/             # Templates de prompts
â”‚   â”œâ”€â”€ retrievers/          # ConfiguraciÃ³n RAG
â”‚   â”œâ”€â”€ agents/              # Agentes conversacionales
â”‚   â””â”€â”€ evaluators/          # EvaluaciÃ³n de LLMs
â”œâ”€â”€ dashboard/               # Capa 6: VisualizaciÃ³n Dash
â”‚   â”œâ”€â”€ app.py               # App principal
â”‚   â”œâ”€â”€ pages/               # PÃ¡ginas (overview, traffic, mapas)
â”‚   â”œâ”€â”€ components/          # Componentes reutilizables
â”‚   â”œâ”€â”€ callbacks/           # Callbacks de Dash
â”‚   â””â”€â”€ assets/              # CSS, JS, imÃ¡genes
â”œâ”€â”€ backend/                 # Capa 7: Backend FastAPI
â”‚   â”œâ”€â”€ api/                 # Endpoints REST
â”‚   â”œâ”€â”€ auth/                # AutenticaciÃ³n JWT
â”‚   â”œâ”€â”€ middleware/          # Middleware personalizado
â”‚   â””â”€â”€ schemas/             # Pydantic models
â”œâ”€â”€ governance/              # Capa 8: Gobernanza de datos
â”‚   â”œâ”€â”€ metadata/            # Registro de metadata
â”‚   â”œâ”€â”€ lineage/             # Data lineage
â”‚   â””â”€â”€ quality/             # ValidaciÃ³n de calidad
â”œâ”€â”€ deployment/              # Capa 9: Despliegue
â”‚   â”œâ”€â”€ docker/              # Dockerfiles
â”‚   â”œâ”€â”€ k8s/                 # Kubernetes (opcional)
â”‚   â””â”€â”€ scripts/             # Scripts de deploy
â”œâ”€â”€ tests/                   # Testing (pytest)
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”œâ”€â”€ docs/                    # DocumentaciÃ³n
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ api/
â”‚   â””â”€â”€ guides/
â”œâ”€â”€ logs/                    # Logs de aplicaciÃ³n
â”œâ”€â”€ .github/                 # GitHub Actions
â”‚   â””â”€â”€ workflows/
â”œâ”€â”€ docker-compose.yml       # OrquestaciÃ³n de servicios
â”œâ”€â”€ requirements.txt         # Dependencias Python
â”œâ”€â”€ pyproject.toml           # ConfiguraciÃ³n de herramientas
â”œâ”€â”€ .env.example             # Template de variables de entorno
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerrequisitos
- Python 3.10+
- Docker & Docker Compose
- Git
- PostgreSQL (o usar Docker)

### InstalaciÃ³n

1. **Clonar el repositorio**
```bash
git clone <repository-url>
cd Centiali-AI
```

2. **Crear entorno virtual**
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Configurar variables de entorno**
```bash
cp .env.example .env
# Editar .env con tus credenciales
```

5. **Levantar infraestructura con Docker**
```bash
docker-compose up -d
```

6. **Ejecutar migraciones de base de datos**
```bash
python data_storage/db_scripts/init_db.py
```

7. **Ejecutar pipeline de ingesta (ejemplo)**
```bash
python data_ingestion/scripts/ingest_csv.py
```

8. **Iniciar dashboard Dash**
```bash
python dashboard/app.py
```

Acceder a: `http://localhost:8050`

## ğŸ“Š Roadmap

### âœ… Fase 1: MVP (Actual)
- [x] ConfiguraciÃ³n de repositorio y estructura
- [ ] Ingesta bÃ¡sica de datos (CSV, API)
- [ ] ETL con pandas y DuckDB
- [ ] Dashboard Dash con KPIs bÃ¡sicos
- [ ] PostgreSQL + Docker

### ğŸš§ Fase 2: AnalÃ­tica Avanzada
- [ ] Modelos predictivos (trÃ¡fico, demanda)
- [ ] Mapas geoespaciales interactivos
- [ ] OrquestaciÃ³n con Airflow/Prefect
- [ ] MLflow para versionado de modelos

### ğŸ”® Fase 3: IA & LLMs
- [ ] IntegraciÃ³n de chat con RAG
- [ ] Reportes automÃ¡ticos con LLMs
- [ ] Soporte a decisiones conversacional
- [ ] Dashboards con insights generados por IA

## ğŸ§ª Testing

```bash
# Ejecutar todos los tests
pytest

# Con cobertura
pytest --cov=. --cov-report=html

# Tests especÃ­ficos
pytest tests/unit/
pytest tests/integration/
```

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crea una rama (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

### EstÃ¡ndares de cÃ³digo
- **Linting**: `black`, `flake8`, `isort`
- **Type hints**: Usar anotaciones de tipo
- **DocumentaciÃ³n**: Docstrings en formato Google/NumPy
- **Testing**: Cobertura mÃ­nima 80%

```bash
# Formatear cÃ³digo
black .

# Linting
flake8 .

# Importaciones
isort .
```

## ğŸ“ Licencia

Este proyecto es desarrollado para la **AlcaldÃ­a de MedellÃ­n** bajo principios de datos abiertos y gobierno abierto.

## ğŸ‘¥ Equipo

- **AlcaldÃ­a de MedellÃ­n** - SecretarÃ­a de Movilidad
- **Equipo de Desarrollo** - Data Engineering & Analytics

## ğŸ“§ Contacto

Para preguntas o soporte: [contacto@medellin.gov.co]

---

**ğŸŒŸ Construyendo una MedellÃ­n inteligente, sostenible y data-driven**
